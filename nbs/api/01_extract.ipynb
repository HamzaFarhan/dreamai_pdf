{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Functions for extracting text segments and embeddings from PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from dreamai_pdf.imports import *\n",
    "from dreamai_pdf.core import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def print_segments(segments: dict, limit: int = 10, width: int = 100):\n",
    "    msg.text(\"-\"*(width + 4), color=\"red\")\n",
    "    # print(\"-\" * (width + 4))\n",
    "    for k, v in segments.items():\n",
    "        msg.text(f\"{k}: {len(v)}\", color=\"green\")\n",
    "        # print(f\"{k}: {len(v)}\")\n",
    "        for s in v[:limit]:\n",
    "            print(\"\\t\", end=\"\")\n",
    "            pprint(s, width=width)\n",
    "            print()\n",
    "        msg.text(\"-\"*(width + 4), color=\"red\")\n",
    "\n",
    "\n",
    "def text_to_segments(\n",
    "    text: Union[str, List[str]],\n",
    "    segs_model: SetFitModel,\n",
    "    thresh: float = 0.6,\n",
    "    classes: List = [\"Work Experience\", \"Education\", \"Certifications\", \"Other\"],\n",
    "):\n",
    "    preds = segs_model.predict(text).detach().cpu().numpy()\n",
    "    probs = segs_model.predict_proba(text).detach().cpu().numpy().max(1)\n",
    "    preds[probs < thresh] = 3\n",
    "    pred_classes = [classes[p] for p in preds]\n",
    "    segments = {pc: [] for pc in classes}\n",
    "    for pc, txt in zip(pred_classes, text):\n",
    "        if txt not in segments[pc]:\n",
    "            segments[pc].append(txt)\n",
    "    return segments, pred_classes, probs\n",
    "\n",
    "\n",
    "def load_segs_model(\n",
    "    model_name: str = \"HamzaFarhan/PDFSegs\", device: Union[str, torch.device] = \"cpu\"\n",
    "):\n",
    "    return SetFitModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "\n",
    "def load_ems_model(\n",
    "    model_name: str = \"HamzaFarhan/PDFSegs\", device: Union[str, torch.device] = \"cpu\"\n",
    "):\n",
    "    return SentenceTransformer(model_name, device=device)\n",
    "\n",
    "\n",
    "def write_segments(segs_model, data_path, output_path=\"pdf_segments\", n_lines=2):\n",
    "    \"\"\"\n",
    "    Extracts text from PDFs and writes segments to JSON files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    segs_model : SetFitModel\n",
    "        SetFit model for segment classification.\n",
    "    data_path : Union[str, Path, List[Union[str, Path]]]\n",
    "        Path to PDFs. Can be a single file, a directory, or a list of files/directories.\n",
    "    output_path : Union[str, Path]\n",
    "        Folder to write JSON files. Defaults to 'pdf_segments'.\n",
    "    n_lines : int\n",
    "        Number of lines to group together when extracting text from PDFs.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    pdfs = resolve_data_path(data_path)\n",
    "    text_dict = extract_text_dict(pdfs, n_lines=n_lines)\n",
    "    for file in pdfs:\n",
    "        try:\n",
    "            pdf_text = text_dict[str(file)]\n",
    "            (segments,) = text_to_segments(pdf_text, segs_model, thresh=0.6)[0]\n",
    "            fn = (output_path / Path(file).stem).with_suffix(\".json\")\n",
    "            with open(fn, \"w\") as f:\n",
    "                json.dump(segments, f, indent=4)\n",
    "        except Exception as e:\n",
    "            msg.fail(f\"\\nCould not write segments for file: {str(file)}\", e)\n",
    "            # print(f\"\\nCould not write segments for file: {str(file)}\\n{e}\")\n",
    "\n",
    "\n",
    "def write_embeddings(\n",
    "    segs_model, ems_model, data_path, output_path=\"pdf_ems\", n_lines=3\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts text from PDFs and writes embeddings to JSON files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    segs_model : SetFitModel\n",
    "        SetFit model for segment classification.\n",
    "    ems_model : SentenceTransformer\n",
    "        SentenceTransformer model for embedding generation.\n",
    "    data_path : Union[str, Path, List[Union[str, Path]]]\n",
    "        Path to PDFs. Can be a single file, a directory, or a list of files/directories.\n",
    "    output_path : Union[str, Path]\n",
    "        Folder to write JSON files. Defaults to 'pdf_ems'.\n",
    "    n_lines : int\n",
    "        Number of lines to group together when extracting text from PDFs.\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    seg_ids = {\"Work Experience\": 1, \"Education\": 2, \"Certifications\": 3, \"Other\": 4}\n",
    "    pdfs = resolve_data_path(data_path)\n",
    "    text_dict = extract_text_dict(pdfs, n_lines=n_lines)\n",
    "    for file in pdfs:\n",
    "        try:\n",
    "            fn = Path(file).stem\n",
    "            pdf_text = text_dict[str(file)]\n",
    "            ems = ems_model.encode(pdf_text)\n",
    "            pred_classes = text_to_segments(pdf_text, segs_model)[1]\n",
    "            for i, data in enumerate(zip(pred_classes, ems)):\n",
    "                pc, em = data\n",
    "                seg_id = seg_ids[pc]\n",
    "                jf = Path(output_path) / f\"{fn}_{seg_id}_{i+1}.json\"\n",
    "                em_dict = {\"id\": fn, \"embedding\": em.tolist()}\n",
    "                with open(jf, \"w\") as f:\n",
    "                    json.dump(em_dict, f)\n",
    "        except Exception as e:\n",
    "            msg.fail(f\"\\nCould not write embeddings for {str(file)}\", e)\n",
    "            # print(f\"\\nCould not write embeddings for {str(file)}\\n{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
